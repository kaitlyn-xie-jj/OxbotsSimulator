% ---------------- Main script (uses theoretical_intrinsics_webots.mat) ----------------
temp_img_path = "../../cache/camera/temp_img.png";
z_constrain = false;
z0 = 0.1; % the constraint height you wanted

% ---- Read the input image ----
I = imread(temp_img_path);

% ---- AprilTag detection ----
tagFamily = "tag36h11";
[ids, loc, detectedFamily] = readAprilTag(I, tagFamily);
if size(loc, 3) == 1
    loc = reshape(loc, size(loc,1), size(loc,2), 1);
end

% ---- Draw markers on detected tag corners ----
for idx = 1:length(ids)
    disp("Detected Tag ID, Family: " + ids(idx) + ", " + detectedFamily(idx));
    
    markerRadius = 2;
    numCorners = size(loc, 1);
    markerPosition = [loc(:, :, idx), repmat(markerRadius, numCorners, 1)];
    
end

% ---- Build output path: same folder, fixed filename ----
[folder, ~, ~] = fileparts(temp_img_path);
output_path = fullfile(folder, "temp_img_recognised.png");

% ---- Save the processed image ----
imwrite(I, output_path);

disp("Detected " + length(ids) + " tags.\n");

% --- reshape/validate loc ---
ids = double(ids(:));
N = numel(ids);
if N == 0
    error('ids empty');
end

% normalize loc into 4x2xN
if isequal(size(loc), [4,2,N])
    loc3 = loc;
elseif ismatrix(loc) && size(loc,1) == N && size(loc,2) == 8
    loc3 = zeros(4,2,N);
    for i=1:N
        row = loc(i,:);
        loc3(:,:,i) = reshape(row,2,4)';
    end
elseif isvector(loc) && numel(loc) == 8*N
    tmp = reshape(loc, [2,4,N]);
    loc3 = permute(tmp, [2,1,3]);
else
    error('loc must be 4x2xN or N x 8 or vector length 8N. Got size %s', mat2str(size(loc)));
end

% --- load theoretical intrinsics and simulated cameraParameters ---
[intr, cameraParams] = load_theoretical_intrinsics();  % intr: cameraIntrinsics, cameraParams: cameraParameters (no distortion)

% --- load tagWorldMap ---
tagWorldMap = load_tagWorldMap();       % helper below

% build id->worldCorners map
mapById = containers.Map('KeyType','double','ValueType','any');
for k = 1:numel(tagWorldMap)
    mapById(double(tagWorldMap(k).id)) = tagWorldMap(k).worldCorners; % 4x3
end

% check availability of estimateWorldCameraPose and estworldpose
hasEstWorld = exist('estimateWorldCameraPose','file') == 2;
hasEstWorldPoseNew = exist('estworldpose','file') == 2;

% ----------------- Combine all tag corners and solve once (estworldpose, no constraints) -----------------
allImgPts = [];    % Nx2 aggregated image points (pixel)
allWorldPts = [];  % Nx3 aggregated world points (meters)
tagPointIdx = [];  % which tag each point belongs to (1..N)
cornerIdx = [];    % which corner index (1..4) per point

for k = 1:N
    id = ids(k);
    corners_img = squeeze(loc3(:,:,k)); % 4x2
    if any(isnan(corners_img(:)))
        warning('Tag %d: some corners NaN, skipping', id);
        % continue;
    end
    if ~isKey(mapById, id)
        warning('Tag %d not in tagWorldMap, skipping', id);
        % continue;
    end
    worldCorners = mapById(id); % 4x3, BL,BR,TR,TL
    
    % undistort points (preferred) - use simulated cameraParams (no distortion)
    try
        ptsUnd = undistortPoints(corners_img, cameraParams); % 4x2
    catch
        ptsUnd = corners_img;
    end
    allImgPts((k-1)*4+1:k*4, :) = ptsUnd;
    allWorldPts((k-1)*4+1:k*4, :) = worldCorners;
end

results = struct([]);
for k = 1:N
    id = ids(k);
    corners_img = squeeze(loc3(:,:,k)); % 4x2
    if any(isnan(corners_img(:)))
        warning('Tag %d: some corners NaN, skipping', id);
        continue;
    end
    if ~isKey(mapById, id)
        warning('Tag %d not in tagWorldMap, skipping', id);
        continue;
    end
    worldCorners = mapById(id); % 4x3, BL,BR,TR,TL
    
    % undistort points (preferred) - use simulated cameraParams (no distortion)
    try
        ptsUnd = undistortPoints(corners_img, cameraParams); % 4x2
    catch
        ptsUnd = corners_img;
    end

    % annotate world coords near detected corners (same as before)
    % I = insertText(I, ptsUnd(:,:), "(" + worldCorners(:,1) + "," + worldCorners(:,2) + ...
    %     "," + worldCorners(:,3) + ")", 'FontSize', 20, 'BoxColor', 'black', 'TextColor', 'white');
    
    % try estworldpose for single-tag case (preferred)
    usedMethod = '';
    orientation = []; location = [];

    if isempty(orientation)
        try
            % estworldpose expects undistorted points and cameraIntrinsics (intr)
            [worldPose, inlierIdx, status] = estworldpose(ptsUnd, worldCorners, intr, ...
                MaxReprojectionError=1, Confidence=95, MaxNumTrials=200);
            if status == 0
                % worldPose.R is camera->world
                R_c2w = worldPose.R;            % camera -> world
                cam_pos = worldPose.Translation; % 1x3
                % keep 'orientation' as world->cam for compatibility with rest of script
                orientation = R_c2w';   % world -> cam
                location = cam_pos;     % camera location in world coords
                usedMethod = 'estworldpose';
            else
                warning('estworldpose status=%d for id=%d. Falling back to extrinsics.', status, id);
            end
        catch ME
            warning('estworldpose failed. Falling back to extrinsics for id=%d.', id);
        end
    end

    % attempt estworldpose/existing methods to get initial guess (optional)
    initialGuess = struct();
    if exist('orientation','var') && exist('location','var') && ~isempty(orientation)
        initialGuess.R_wc = orientation; % world->cam
        initialGuess.camPos = location;  % cam position in world (1x3)
    end
    
    if z_constrain == true
        % now call constrained estimator with fixed z
        try
            [R_wc_opt, camPos_world_opt, usedTag, resnorm] = estimatePoseFixedZ(worldCorners, ptsUnd, intr, z0, initialGuess);
            % convert to your script vars: orientation (world->cam), location (1x3), R_c2w etc.
            orientation = R_wc_opt;               % world->cam
            location = camPos_world_opt;          % camera position in world
            usedMethod = usedTag;
        catch ME
            warning('estimatePoseFixedZ failed: %s. Falling back to previous methods.', ME.message);
            % keep previous orientation/location if exist
        end
    end
    
    % if not solved by estworldpose (or N>1), try estimateWorldCameraPose (original behavior) or extrinsics fallback
    if isempty(orientation)
        if hasEstWorld
            try
                % estimateWorldCameraPose accepts cameraParameters or cameraIntrinsics (we pass cameraParams)
                [orientation, location, inlierIdx] = estimateWorldCameraPose(ptsUnd, worldCorners, cameraParams, ...
                    'MaxReprojectionError', 4, 'Confidence', 99);
                usedMethod = 'estimateWorldCameraPose';
            catch ME
                warning('estimateWorldCameraPose failed for id=%d: %s. Falling back to extrinsics.', id, ME.message);
            end
        end
    end
    
    % fallback to extrinsics if necessary (extrinsics requires cameraParameters)
    if isempty(orientation)
        try
            [R_ex, t_ex] = extrinsics(ptsUnd, worldCorners, cameraParams);
            % extrinsics returns R_ex (world->cam) and t_ex (1x3) such that:
            % X_cam = R_ex * X_world' + t_ex'
            orientation = R_ex;
            % derive camera location in world coords: solve for location where X_world = location gives X_cam=0:
            % 0 = R_ex * location' + t_ex'  => location' = -R_ex' * t_ex'
            location = (-orientation' * t_ex')';
            usedMethod = 'extrinsics';
        catch ME
            warning('extrinsics failed for id=%d: %s. Skipping.', id, ME.message);
            continue;
        end
    end
    
    % Build T_world_from_cam
    % orientation maps world->cam. Camera-to-world rotation = orientation'
    R_c2w = orientation';
    % location is camera position in world coords (1x3)
    cam_pos = location(:)'; % ensure row
    T_world_from_cam = eye(4);
    T_world_from_cam(1:3,1:3) = R_c2w;
    T_world_from_cam(1:3,4) = cam_pos';
    
    % For reprojection: need extrinsics R_ex/t_ex. Use intr for worldToImage
    t_ex = (-(orientation * cam_pos'))'; % 1x3
    
    % reprojection check (project worldCorners -> image pixels) using intr/cameraParams as appropriate
    % proj = worldToImage(intr, orientation, cam_pos, worldCorners);
    tform = rigidtform3d(R_c2w, cam_pos);                           
    proj = world2img_manual(allWorldPts, tform, intr); 
    
    radcircle = 5 * ones(size(proj, 1), 1);
    I = insertShape(I, "Circle", [allImgPts, radcircle], ShapeColor="red", Opacity=1);
    radcircle = 3 * ones(size(proj, 1), 1);
    I = insertShape(I, "Circle", [proj, radcircle], ShapeColor="green", Opacity=1);
    
    reprojErrs = sqrt(sum((proj - allImgPts).^2, 2));
    meanReproj = mean(reprojErrs);
    
    % convert orientation->euler/quaternion for readability (camera-to-world rotation)
    quat = rotm2quat(R_c2w); % [w x y z]
    eulZYX = rotm2eul(R_c2w, 'ZYX'); % rad
    
    % pack result
    res.id = id;
    res.corners_img = corners_img;
    res.corners_undistorted = ptsUnd;
    res.worldCorners = worldCorners;
    res.method = usedMethod;
    res.orientation = orientation; % world->cam
    res.location = cam_pos;        % camera position in world
    res.T_world_from_cam = T_world_from_cam;
    res.cam_position_world = cam_pos;
    res.quat_wxyz = quat;
    res.eulZYX_deg = rad2deg(eulZYX);
    res.reprojPerCorner = reprojErrs;
    res.meanReproj = meanReproj;
    
    results = [results; res]; %#ok<AGROW>
end

figure;
imshow(I); hold off;

% print brief summary
fprintf('Per-tag estimation done. %d results produced.\n', numel(results));
for i=1:numel(results)
    fprintf(' id=%2d  method=%s  meanReproj=%.3f px  camPos=[%.3f %.3f %.3f]\n', ...
        results(i).id, results(i).method, results(i).meanReproj, results(i).cam_position_world);
end
fprintf('Use showExtrinsics(results, cameraParams) to visualize.\n');
showExtrinsics(results, cameraParams);

%% ---------------- helper: load_theoretical_intrinsics ----------------
function [intr, cameraParams] = load_theoretical_intrinsics()
    % Try to load a cameraIntrinsics object from several candidate paths
    candidates = { fullfile(pwd,'theoretical_intrinsics_webots.mat'), ...
                   fullfile(pwd,'..','..','cache','camera','theoretical_intrinsics_webots.mat'), ...
                   fullfile('..','cache','camera','theoretical_intrinsics_webots.mat'), ...
                   fullfile(pwd,'intrinsics_webots.mat'), ...
                   fullfile(pwd,'..','..','cache','camera','intrinsics_webots.mat') };
    intr = [];
    for i=1:numel(candidates)
        f = candidates{i};
        if exist(f,'file')
            s = load(f);
            fn = fieldnames(s);
            % accept either variable named 'intr' or first variable that is cameraIntrinsics-like
            if isfield(s,'intr')
                intr = s.intr;
            else
                % try to find cameraIntrinsics in file
                intr = s.(fn{1});
            end
            break;
        end
    end
    if isempty(intr)
        error('theoretical_intrinsics_webots.mat not found. Save a cameraIntrinsics variable named ''intr'' into one of the candidate paths.');
    end

    % build a cameraParameters object with zero distortion for functions that expect cameraParameters
    try
        imageSize = intr.ImageSize;
        fxfy = intr.FocalLength;
        pp = intr.PrincipalPoint;
        % cameraParameters requires IntrinsicMatrix (3x3) with MATLAB convention
        camMat = intr.IntrinsicMatrix; % cameraIntrinsics stores IntrinsicMatrix property
        % create cameraParameters with zero distortion
        cameraParams = cameraParameters('IntrinsicMatrix', camMat, 'ImageSize', imageSize, ...
            'RadialDistortion',[0 0], 'TangentialDistortion',[0 0]);
    catch ME
        error('Failed to construct cameraParameters from intr: %s', ME.message);
    end
end

%% ---------------- helper: load_tagWorldMap ----------------
function tagWorldMap = load_tagWorldMap()
    candidates = { fullfile(pwd,'tagWorldMap.mat'), fullfile(pwd,'..','..','cache','camera','tagWorldMap.mat'), fullfile('..','cache','camera','tagWorldMap.mat') };
    for i=1:numel(candidates)
        f = candidates{i};
        if exist(f,'file')
            s = load(f);
            if isfield(s,'tagWorldMap')
                tagWorldMap = s.tagWorldMap;
            else
                fn = fieldnames(s); tagWorldMap = s.(fn{1});
            end
            return;
        end
    end
    error('tagWorldMap.mat not found. Generate it with the provided generator and place it in current folder or ../../cache/camera/ .');
end

%% ---------------- visualization: showExtrinsics ----------------
function showExtrinsics(results, cameraParams)
    if nargin < 2
        cameraParams = load_theoretical_intrinsics(); % returns [intr, cameraParams]; we only need cameraParams here
        cameraParams = cameraParams{2};
    end
    if isempty(results)
        error('results empty');
    end
    figure('Name','Per-tag Extrinsics (estimateWorldCameraPose)','Color','w'); hold on; grid on; axis equal;
    xlabel('X (m)'); ylabel('Y (m)'); zlabel('Z (m)');
    for i=1:numel(results)
        wc = results(i).worldCorners; % 4x3
        patch('XData', wc(:,1), 'YData', wc(:,2), 'ZData', wc(:,3), 'FaceColor', [0.9 0.9 0.9], 'FaceAlpha', 0.6);
        plot3([wc(:,1); wc(1,1)], [wc(:,2); wc(1,2)], [wc(:,3); wc(1,3)], '-k', 'LineWidth', 1);
        cen = mean(wc,1);
        text(cen(1), cen(2), cen(3), sprintf('id=%d', results(i).id), 'FontSize', 9, 'Color', 'k');
    end
    % draw cameras
    for i=1:numel(results)
        T = results(i).T_world_from_cam;
        drawCameraFrustum(T, cameraParams, 0.3, 0.1);
        pos = results(i).cam_position_world;
        text(pos(1), pos(2), pos(3), sprintf('id=%d e=%.2fpx', results(i).id, results(i).meanReproj), 'Color','b');
    end

    % ---------- Enable interactive view controls ----------
    view(3);                         % 3D view
    axis vis3d                      % keep aspect during rotation
    camorbit(20,-10);               % initial camera orbit
    rotate3d on                     % enable mouse rotation (left-drag)
    % show camera toolbar and set to orbit mode (better interactive controls)
    hFig = gcf;
    cameratoolbar(hFig,'Show');
    cameratoolbar(hFig,'SetMode','orbit'); 
    % optionally enable zoom and pan with mouse/toolbar
    % zoom on;
    % pan on;
    % You can toggle tools in the figure toolbar or call zoom/pan programmatically.
    % ----------------------------------------------------

    hold off;
    title('Per-tag camera poses (world frame) - one pose per tag');
end

%% ---------------- draw frustum helper ----------------
function drawCameraFrustum(T_world_from_cam, cameraParams, depth, axisScale)
    if nargin<3, depth = 0.5; end
    if nargin<4, axisScale = 0.1; end
    if isprop(cameraParams,'Intrinsics')
        intr = cameraParams.Intrinsics;
    else
        intr = cameraParams;
    end
    imgSize = intr.ImageSize; W = imgSize(2); H = imgSize(1);
    fx = intr.FocalLength(1); fy = intr.FocalLength(2);
    cx = intr.PrincipalPoint(1); cy = intr.PrincipalPoint(2);
    imgPts = [1 1; W 1; W H; 1 H]; % TL TR BR BL
    camPts = zeros(4,3);
    for k=1:4
        u = imgPts(k,1); v = imgPts(k,2);
        x = (u - cx) / fx; y = (v - cy) / fy;
        camPts(k,:) = [x*depth, y*depth, depth];
    end
    P = [camPts'; ones(1,4)];
    Pw = (T_world_from_cam * P)'; originw = (T_world_from_cam * [0 0 0 1]')'; originw = originw(1:3);
    plot3([originw(1); Pw(:,1)], [originw(2); Pw(:,2)], [originw(3); Pw(:,3)], '-r');
    patch(Pw(:,1), Pw(:,2), Pw(:,3), 'r', 'FaceAlpha', 0.05, 'EdgeColor', 'r');
    R = T_world_from_cam(1:3,1:3);
    xs = originw + axisScale*(R(:,1)'); ys = originw + axisScale*(R(:,2)'); zs = originw + axisScale*(R(:,3)');
    plot3([originw(1) xs(1)], [originw(2) xs(2)], [originw(3) xs(3)], '-','Color',[0.8 0 0],'LineWidth',2);
    plot3([originw(1) ys(1)], [originw(2) ys(2)], [originw(3) ys(3)], '-','Color',[0 0.6 0],'LineWidth',2);
    plot3([originw(1) zs(1)], [originw(2) zs(2)], [originw(3) zs(3)], '-','Color',[0 0 0.8],'LineWidth',2);
end